import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import random
from tqdm import tqdm
from pathlib import Path
import json


# --- å¯¼å…¥ä½ çš„æ¨¡å— ---
from Industrial_Pipeline_Functions import (
    LightweightIndustrialDiffusion,
    load_ipps_problem_from_json,
    get_ipps_problem_data,
    validate_constraints
)
from Evaluate import (
    load_problem_definitions,
    simulate_complete_scheduling,
    graph_to_simulation_input
)
# å‡è®¾ generate_random_ipps_problem åœ¨ Generate_Problem.py ä¸­
from Generate_random_problem_instances import generate_random_ipps_problem

# ================= é…ç½®åŒºåŸŸ =================
MODEL_PATH = "rl_checkpoints/rl_multi_generalization_BATCH_SIZE16_T_STEPS4/model_ep1999.pth"
TEST_SIZES = [10, 30, 50, 100]  # è¦æµ‹è¯•çš„å·¥ä»¶æ•°é‡ (Job sizes)
NUM_INSTANCES = 10  # æ¯ä¸ªå°ºå¯¸ç”Ÿæˆå¤šå°‘ä¸ªé—®é¢˜
NUM_MACHINES = [5, 5, 10, 10]  # å›ºå®šæœºå™¨æ•°é‡ï¼Œæ¨¡æ‹Ÿè½¦é—´è§„æ¨¡
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

T_STEPS = 4
HIDDEN_DIM = 256
TIME_GUIDANCE_SCALE = 0.001

# ===========================================

def run_random_baseline(workpieces_objs, machine_power_data):
    """
    éšæœºåŸºçº¿ï¼šéšæœºé€‰æ‹©æœºå™¨ï¼Œéšæœºç”Ÿæˆä¼˜å…ˆçº§
    """
    workpiece_cycles = []

    for wp in workpieces_objs:
        selected_machines = []
        processing_times = []

        for feat_idx in range(len(wp.optional_machines)):
            options = wp.optional_machines[feat_idx]
            times = wp.processing_time[feat_idx]

            # 1. éšæœºé€‰æ‹©ä¸€ä¸ªåˆæ³•æœºå™¨
            rand_idx = random.randint(0, len(options) - 1)
            machine_id = options[rand_idx]
            proc_time = times[rand_idx]

            selected_machines.append(machine_id)
            processing_times.append(proc_time)

        # 2. ä¼˜å…ˆçº§å°†åœ¨ simulate_complete_scheduling å†…éƒ¨éšæœºç”Ÿæˆ (ä¼ å…¥3å…ƒç»„)
        workpiece_cycles.append((wp.name, selected_machines, processing_times))

    # è¿è¡Œæ¨¡æ‹Ÿ
    _, energy_report, _ = simulate_complete_scheduling(workpiece_cycles, machine_power_data)
    return energy_report['total']['makespan'], energy_report['total']['total_energy']


def run_ai_solver(model, problem_file, workpieces_objs, machine_power_data, device):

    # 1. æ„å»ºç”»å¸ƒ
    raw_wp_dicts, raw_machines = load_ipps_problem_from_json(problem_file)
    ipps_canvas = get_ipps_problem_data(raw_wp_dicts, raw_machines, device)

    # 2. æ¨¡å‹æ¨ç†
    # æ³¨æ„ï¼šæ¨ç†æ—¶å¯ä»¥è°ƒé«˜ time_guidance_scale æ¥å¢å¼ºå¼•å¯¼
    generated_edges, _, _, priorities = model.reverse_diffusion_with_logprob(
        ipps_canvas, device, time_guidance_scale=TIME_GUIDANCE_SCALE
    )

    edges_matrix = generated_edges.argmax(dim=-1).detach().cpu()

    # 3. éªŒè¯ç»“æ„åˆæ³•æ€§
    node_labels = ipps_canvas.x.argmax(dim=1)
    is_valid = validate_constraints(edges_matrix, node_labels, device, exact=True, data=ipps_canvas)

    if not is_valid:
        print('invalid graph')
        return float('inf'), float('inf')  # æ ‡è®°ä¸ºå¤±è´¥

    # 4. è½¬æ¢å¹¶æ¨¡æ‹Ÿ
    try:
        wp_cycles = graph_to_simulation_input(edges_matrix, ipps_canvas, workpieces_objs, priorities)
        _, energy_report, _ = simulate_complete_scheduling(wp_cycles, machine_power_data)
        return energy_report['total']['makespan'], energy_report['total']['total_energy']
    except Exception as e:
        print(f"Sim Error: {e}")
        return float('inf'), float('inf')


def main():
    # --- 1. åŠ è½½æ¨¡å‹ ---
    print(f"ğŸ”„ Loading model from {MODEL_PATH}...")
    model = LightweightIndustrialDiffusion(T=T_STEPS, hidden_dim=HIDDEN_DIM, num_layers=6, nhead=4, dropout=0.1, device=DEVICE).to(
        DEVICE)
    # model = LightweightIndustrialDiffusion(
    #     T=T_STEPS,
    #     hidden_dim=HIDDEN_DIM,
    #     use_projector=True,  # æ¨ç†æ—¶å¼€å¯ Projector åŒé‡ä¿é™©
    #     device=DEVICE
    # ).to(DEVICE)

    try:
        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
        model.eval()
    except FileNotFoundError:
        print("âŒ Model file not found. Please check the path.")
        return

    results = []

    # --- 2. æµ‹è¯•å¾ªç¯ ---
    print("\nğŸš€ Starting Generalization Test...")

    temp_dir = Path("TestSet/Generalization_Temp")
    temp_dir.mkdir(parents=True, exist_ok=True)

    for n_jobs, n_machines in zip(TEST_SIZES, NUM_MACHINES):
        print(f"\nğŸ“¦ Testing Problem Size: {n_jobs} Jobs (generating {NUM_INSTANCES} instances)...")

        model_makespans = []
        random_makespans = []

        for i in tqdm(range(NUM_INSTANCES)):
            # A. ç”Ÿæˆéšæœºé—®é¢˜
            problem_file = temp_dir / f"gen_{n_jobs}_job_{i}.json"
            generate_random_ipps_problem(
                filename=str(problem_file),
                num_machines=n_machines,
                num_workpieces=n_jobs,
                min_ops=4, max_ops=8,  # éšæœºå·¥åºé•¿åº¦
                min_opts=2, max_opts=4,  # æŸ”æ€§ç¨‹åº¦
                seed=None  # ä¸è®¾ç§å­ä»¥ä¿è¯éšæœºæ€§
            )

            # B. åŠ è½½é—®é¢˜å®šä¹‰
            workpieces_objs, machine_power_data = load_problem_definitions(str(problem_file))

            # C. è¿è¡Œ Random Baseline
            # è¿è¡Œ 3 æ¬¡å–æœ€å¥½ï¼Œä½œä¸ºå¼ºä¸€ç‚¹çš„ Baseline
            rand_mk_sum = 0
            for _ in range(3):
                r_mk, _ = run_random_baseline(workpieces_objs, machine_power_data)
                rand_mk_sum += r_mk

            avg_rand_mk = rand_mk_sum / 3
            random_makespans.append(avg_rand_mk)

            model_mk_sum = 0
            with torch.no_grad():
                for _ in range(3):
                    mk, _ = run_ai_solver(model, str(problem_file), workpieces_objs, machine_power_data, DEVICE)
                    model_mk_sum += mk

            model_mk = model_mk_sum / 3
            model_makespans.append(model_mk)

        avg_model = np.mean(model_makespans)
        avg_rand = np.mean(random_makespans)
        improvement = (avg_rand - avg_model) / avg_rand * 100

        print(f"   ğŸ‘‰ Size {n_jobs}: Random Avg={avg_rand:.1f}, Model Avg={avg_model:.1f}, Improv={improvement:.1f}%")

        results.append({
            "Size": n_jobs,
            "Random_Makespan": avg_rand,
            "AI_Makespan": avg_model,
            "Improvement_Pct": improvement,
            "AI_Raw": model_makespans,
            "Random_Raw": random_makespans
        })

    output_file = "generalization_test_results.json"
    print(f"\nğŸ’¾ Saving results to {output_file}...")
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=4)
        print("âœ… Save successful!")
    except Exception as e:
        print(f"âŒ Save failed: {e}")

    # --- 3. å¯è§†åŒ–ç»“æœ ---
    plot_results(results)


def plot_results(results):
    sizes = [r["Size"] for r in results]
    rand_means = [r["Random_Makespan"] for r in results]
    ai_means = [r["AI_Makespan"] for r in results]

    x = np.arange(len(sizes))
    width = 0.35

    fig, ax = plt.subplots(figsize=(10, 6))
    rects1 = ax.bar(x - width / 2, rand_means, width, label='Random (Avg. of 3 runs)', color='gray', alpha=0.7)
    rects2 = ax.bar(x + width / 2, ai_means, width, label='Model (Avg. of 3 runs)', color='royalblue', alpha=0.9)

    ax.set_xlabel('Problem Size (Number of Jobs)')
    ax.set_ylabel('Average Makespan (Lower is Better)')
    ax.set_title(f'Tested on 10 instances per problem size')
    ax.set_xticks(x)
    ax.set_xticklabels(sizes)
    ax.legend()

    # æ ‡æ³¨æå‡ç™¾åˆ†æ¯”
    for i, rect in enumerate(rects2):
        height = rect.get_height()
        improv = results[i]["Improvement_Pct"]
        ax.annotate(f'-{improv:.1f}%',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points vertical offset
                    textcoords="offset points",
                    ha='center', va='bottom', fontweight='bold', color='green')

    plt.tight_layout()
    plt.savefig("Generalization_Test_Result.png", dpi=300)
    print("\nâœ… Test finished! Result saved to 'Generalization_Test_Result.png'")
    plt.show()


if __name__ == "__main__":
    json_file = "generalization_test_results.json"
    with open(json_file, 'r', encoding='utf-8') as f:
        results_data = json.load(f)

    plot_results(results_data)
    # main()